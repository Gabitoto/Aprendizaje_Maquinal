{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSfy1i1uG2CH"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.4)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Pc/Desktop/TUPED/Aprendizaje Automatico/Practica/Semana V/AM_Clustering/venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from IPython.display import Image, display\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EBWmC4KCG3lA"
   },
   "outputs": [],
   "source": [
    "%cd '/content/drive/MyDrive/Inteligencia Artificial/IA - Clases de PraÃÅctica/ContenidosPorTemas/ActividadesPracticas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V5ZVafTI2CX8"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8FOUGtmzfLq"
   },
   "source": [
    "### Segmentaci√≥n de clientes üë©ü§†üßë\n",
    "\n",
    "El siguiente conjunto de datos consiste en informaci√≥n sobre el comportamiento de compra de 2,000 individuos de una determinada √°rea al entrar en una tienda f√≠sica de bienes de consumo r√°pido. Todos los datos se han recopilado a trav√©s de las tarjetas que utilizan al momento de pagar. Los datos han sido preprocesados y no hay valores faltantes. Adem√°s, el volumen del conjunto de datos se ha limitado y anonimizado para proteger la privacidad de los clientes.\n",
    "\n",
    "Columnas del conjunto de datos:\n",
    "\n",
    "- **Sex**: g√©nero.\n",
    "        0: masculino,\n",
    "        1: femenino.\n",
    "- **Marital status**: Estado civil de un cliente.\n",
    "        0: soltero,\n",
    "        1: no soltero (divorciado/separado/casado/viudo).\n",
    "- **Age**: Edad del cliente en a√±os. Valor m√≠nimo: 18, Valor m√°ximo: 78.\n",
    "- **Education**: Nivel educativo del cliente.\n",
    "        0: otro/desconocido,\n",
    "        1: escuela secundaria,\n",
    "        2: universidad,\n",
    "        3: posgrado.\n",
    "- **Income**: Ingreso anual autoreportado en d√≥lares estadounidenses del cliente. Valor m√≠nimo: 35,832, Valor m√°ximo: 309,364.\n",
    "- **Occupation**: Categor√≠a de la ocupaci√≥n del cliente.\n",
    "        0: desempleado/no calificado,\n",
    "        1: empleado calificado/funcionario,\n",
    "        2: administraci√≥n/aut√≥nomo/empleado altamente calificado/oficial.\n",
    "- **Settlement size**: Tama√±o de la ciudad donde vive el cliente.\n",
    "        0: ciudad peque√±a,\n",
    "        1: ciudad mediana,\n",
    "        2: gran ciudad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema es que tenemos muchas variables (edad, ingresos, estado civil, etc.), y no es f√°cil trabajar con todas a la vez. Vamos a usar una t√©cnica muy √∫til: An√°lisis de Componentes Principales (PCA, por sus siglas en ingl√©s: Principal Component Analysis).\n",
    "\n",
    "¬øQu√© hace PCA?\n",
    "\n",
    "- Reduce la dimensionalidad de los datos, es decir, transforma muchas variables en unas pocas nuevas llamadas componentes principales.\n",
    "- Estas nuevas variables son combinaciones lineales de las originales y est√°n ordenadas de forma que:\n",
    "\n",
    "    - La primera componente explica la mayor parte de la variabilidad en los datos.\n",
    "    - La segunda componente explica la mayor parte de la variabilidad que queda, y as√≠ sucesivamente.\n",
    "\n",
    "De esta manera podemos simplificar los datos, visualizarlos en 2D o 3D y usarlos como entrada para algoritmos de clustering sin perder demasiada informaci√≥n.\n",
    "\n",
    "```\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(\"Varianza explicada por cada componente:\", pca.explained_variance_ratio_)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Twzc_VZ32wH7"
   },
   "source": [
    "### Actividad\n",
    "\n",
    "Con los datos reducidos (X_pca) aplique los tres m√©todos distintos de clustering:\n",
    "\n",
    "K-Means: elegir el valor de K usando m√©todo del codo y/o de silueta.\n",
    "DBSCAN: detectar densidades y posibles outliers.\n",
    "Jer√°rquico (Agglomerative): formar clusters basados en similitud.\n",
    "\n",
    "La **segmentaci√≥n de clientes** (**customer segmentation**) es una estrategia y t√©cnica en marketing y an√°lisis de datos que implica dividir una base de clientes en grupos m√°s peque√±os y homog√©neos seg√∫n caracter√≠sticas y comportamientos similares. El objetivo principal de la segmentaci√≥n de clientes es comprender mejor a los diferentes grupos de clientes para poder adaptar estrategias y enfoques de marketing espec√≠ficos a cada segmento.\n",
    "\n",
    "Luego de probar los distintos m√©todos, seleccionar uno y agrupar en el n√∫mero de clusters seleccionado. Con las etiquetas asignadas por el m√©todo, filtrar el dataset original y describir en t√©rminos de las caracter√≠sticas originales cada uno de los grupos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLTXMW9vQUTT"
   },
   "outputs": [],
   "source": [
    "# Cargo los datos\n",
    "df = pd.read_csv(\"1_datos/customer_data.csv\", delimiter=\",\", header=0)\n",
    "datum = pd.DataFrame(df)\n",
    "datum.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Analisis de datos: Basico\n",
    "\n",
    "datum.info()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=datum, x=\"Sex\", hue=\"Education\")\n",
    "plt.title(\"Distribuci√≥n de Educaci√≥n por Sexo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PairGrid\n",
    "g = sns.PairGrid(datum[['Age', 'Income','Education']], hue='Education')\n",
    "g.map_upper(sns.scatterplot)\n",
    "g.map_lower(sns.scatterplot)\n",
    "g.map_diag(sns.histplot)\n",
    "g.add_legend()\n",
    "plt.suptitle('PairGrid Personalizado', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrego mas visualizaciones de variables\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Mix de Gr√°ficos con Seaborn', fontsize=16, fontweight='bold')\n",
    "    \n",
    "# Gr√°fico 1: Violin plot\n",
    "sns.violinplot(data=datum, x='Sex', y='Age', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Violin Plot: Edad por Categor√≠a')\n",
    "    \n",
    "# Gr√°fico 2: Heatmap de correlaci√≥n\n",
    "corr_data = datum[['x', 'y', 'Settlement size', 'Income']].corr()\n",
    "sns.heatmap(corr_data, annot=True, cmap='coolwarm', center=0, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Matriz de Correlaci√≥n')\n",
    "    \n",
    "# Gr√°fico 3: Strip plot\n",
    "sns.stripplot(data=datum, x='Marital status', y='Occupation', hue='Occupation', ax=axes[0, 2])\n",
    "axes[0, 2].set_title('Strip Plot: Salario por Grupo')\n",
    "axes[0, 2].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "# Gr√°fico 4: Regression plot\n",
    "sns.regplot(data=datum, x='Age', y='Income', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Regresi√≥n: Edad vs Salario')\n",
    "    \n",
    "# Gr√°fico 5: Bar plot\n",
    "sns.barplot(data=datum, x='categoria', y='salario', hue='grupo', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Salario Promedio por Categor√≠a y Grupo')\n",
    "    \n",
    "# Gr√°fico 6: KDE plot\n",
    "sns.kdeplot(data=datos, x='edad', y='salario', ax=axes[1, 2])\n",
    "axes[1, 2].set_title('Densidad: Edad vs Salario')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamos los datos\n",
    "\n",
    "# 1. Seleccionar las columnas que quer√©s escalar\n",
    "cols = [\"ID\", \"ingresos\"]\n",
    "\n",
    "# 2. Crear el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 3. Ajustar y transformar\n",
    "X_scaled = scaler.fit_transform(df[cols])\n",
    "\n",
    "# 4. Pasar el resultado a DataFrame con los mismos nombres de columnas\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=cols)\n",
    "\n",
    "print(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Aplico PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(datum)\n",
    "\n",
    "print(\"Varianza explicada por cada componente:\", pca.explained_variance_ratio_)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP4HsZBFz3Te7EIfnXDrEyC",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
